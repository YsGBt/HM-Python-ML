# 机器学习_周志华
## 术语
- `模型 "model" / 学习器 "learner"`: 数据中学习的结果

- `数据集 "data set"`: 记录的集合

- `样本 "sample" / 示例 "instance"`: 一个事件或对象  

- `属性 "attribute" / 特征 "feature"`: 反映事件或对象在某方面的表现或性质的事项

- `属性值 "attribute value"`: 属性上的取值

- `属性空间 "attribute space" / 样本空间 "sample space"`: 属性张成的空间

- `维数 "dimensionality"`: 令 $D = \{x_1, x_2, ..., x_m\}$ 表示包括 $m$ 个样本的数据集，每个样本由 $d$ 个属性描述，则每个样本 $x_i = (x_{i1}; x_{i2}; ...; x_{id})$ 是 $d$ 维样本空间 $\chi$ 中的一个向量，$x \in \chi$，其中 $x_{ij}$ 是 $x_i$ 在第 $j$ 个属性上的取值， $d$ 称为样本 $x_i$ 的 "维数"

- `训练数据 "training data"`: 训练过程中使用的数据

- `训练样本 "training sample"`: 训练数据中的每个样本

- `训练集 "training set"`: 训练样本组成的集合，是训练数据的子集

- `假设 "hypothesis"`: 学得模型对应了关于数据的某种潜在的规律，因此亦称"假设"

- `真相 / 真实 "ground-truth"`: 潜在规律自身 (学习过程就是为了找出或逼近真相)

- `标记 "label"`: 样本训练的"结果"信息 (例如，((色泽=绿;敲声=浑浊)，好瓜) 中的 "好瓜")

- `样例 "example"`: 拥有了标记信息的样本，一般用 $(x_i, y_i)$ 表示第 $i$ 个样例

- `标记空间 "label space" / 输出空间`: $y_i \in \Upsilon$ 是样本 $x_i$ 的标记，$\Upsilon$ 是所有标记的集合，亦称标记空间

- `分类 "classification"`: 预测离散值的学习任务

- `回归 "regression"`: 预测连续值的学习任务

- `二分类 "binary classification"`: 只涉及两个类别的"二分类"学习任务，通常称其中一个类为"正类" (positive class)，另一个类为"反类" (negative class)

- `多分类 "multi-class classification"`: 涉及多个类别的"多分类"学习任务

- `测试 "testing"`: 使用模型进行预测的过程

- `测试样本 "testing sample"`: 被预测的样本

- `聚类 "clustering"`: 将训练集中的样本分成若干组，每组称为一个"簇" (cluster); 自动形成的簇可能对应一些潜在的概念划分

- `监督学习 "supervised learning"`: 代表有分类和回归

- `无监督学习 "unsupervised learning"`: 代表有聚类

- `泛化能力 "generalization"`: 学得模型适用于新样本的能力

- `版本空间 "version space"`: 多个假设与训练集一致，即存在着一个与训练集一致的"假设集合"，称为"版本空间"

- `归纳偏好 "inductive bias"`: 机器学习算法在学习过程中对某种类型假设的偏好 (例如，算法偏好尽可能"特殊"的模型)

- `奥卡姆剃刀 "Occam's razor"`: 若有多个假设与观察一致，则选最简单的那个

- `错误率 "error rate"`: 分类错误的样本数占样本总数的比率，即如果在 $m$ 个样本中有 $a$ 个样本分类错误，则错误率 $E = \frac{a}{m}$

- `精度 "accuracy"`: $1 - \frac{a}{m}$ 称为"精度" (accuracy)，即 "精度 = 1 - 错误率"

- `误差 "error"`: 机器学习的实际预测输出与样本的真实输出之间的差异，机器学习在训练集上的误差称为"训练误差" (training error) 或"经验误差" (empirical error)，在新样本上的误差称为"泛化误差" (generalication error)

- `过拟合 "overfitting" / 过配`: 当模型把训练样本学得"太好"了的时候 (可能已经把训练样本自身的一些特点当作了所有潜在样本都会具有的一般性质)

- `欠拟合 "underfitting" / 欠配`: 模型对训练样本的一般性质尚未学好

- `分层采样 "stratified sampling"`: 保留类别比例的采样方式

- `留出法 "hold-out"`: 将数据集 $D$ 划分为两个互斥的集合，其中一个集合作为训练集 $S$，另一个作为测试集 $T$，即 $D = S \cup T$，$S \cap T = \empty$。常见的做法是将大约 $\frac{2}{3}$ ~ $\frac{4}{5}$ 的样本用于训练，剩余样本用于测试。另外，在使用留出法时，一般要采用若干次随机划分、重复进行实验评估后取平均值作为留出法的评估结果

- `交叉验证法 "cross validation"`: 将数据集 $D$ 划分为 $k$ 个大小相似的互斥子集，即 $D = D_1 \cup D_2 \cup .. \cup D_k$，$D_i \cap D_j = \empty$ $(i \neq j)$。每个子集 $D_i$ 都尽可能保持数据分布的一致性，即从 $D$ 中通过分层采样得到。然后，每次用 $k - 1$ 个子集的并集作为训练集，余下的那个子集作为测试集；这样就可以获得 $k$ 组训练/测试集，从而可进行 $k$ 次训练和测试，最终返回的是这 $k$ 个测试结果的均值。 $k$ 的常用取值是 10，此时称为10折交叉验证。 与留出法相似，$k$ 折交叉验证通常要随机使用不同的划分重复 $p$ 次，最终的评估结果是这 $p$ 次 $k$ 折交叉验证结果的均值

- `留一法 "leave-one-out"`: 只用一个样本作为测试集

- `自助法 "bootstrapping"`: 给定包含 $m$ 个样本的数据集 $D$，我们对它进行采样产生数据集 $D'$：每次随机从 $D$ 中条寻一个样本，将其拷贝放入 $D'$，然后再将该样本放回初始数据集 $D$ 中；这个过程重复执行 $m$ 次后，我们就得到了包含 $m$ 个样本的数据集 $D'$。显然 $D$ 中有一部分样本会在 $D'$ 中多次出现，而另一部分样本不出现。样本在 $m$ 次采样中始终不被采到的概率是 $(1 - \frac{1}{m})^m$，取极限得到 
    $$\lim_{m \to \infty}(1 - \frac{1}{m})^m \to \frac{1}{e} \approx 0.386$$
    即初始数据集 $D$ 中约有 $36.8\%$ 的样本从未出现在采样数据集 $D'$ 中。于是我们可以将 $D'$ 用作训练集，$D' \setminus D$ 用作测试集。这样的测试结果，亦称"包外估计" (out-of-bag estimate)









